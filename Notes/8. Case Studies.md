## LeNet-5

![LeNet-5](/Notes/8.%20Case%20Studies/lenet5.png)


## AlexNet

![AlexNet](/Notes/8.%20Case%20Studies/AlexNet.png)

Local response normalization takes all the channels for a particular height and width and normalizes them. It doesn't have a huge impact so its not in use as much.

## VGG-16

A very simplified network.

![VGG16](/Notes/8.%20Case%20Studies/VGG16.png)

## ResNet

ResNet uses a shortcut.

The activats of laye a[l] are added to z[l+2] and then tis sum is passed through the activation function to get a[l+2].

![ResNet](/Notes/8.%20Case%20Studies/ResNet.png)

![ResNet2](/Notes/8.%20Case%20Studies/resnet2.png)

We see that making your networks deeper could hurt the accuracy.

## 1x1 Convolutions

![1x1 convolution](/Notes/8.%20Case%20Studies/1x1%20convolutions.png)

It allows us to chnage the number of channels. It also helps us add non-linearity.

## Inception network

The idea is that instead of using one filter or pooling, you can use all of them and concatenate all the outputs.

![Inception Network](/Notes/8.%20Case%20Studies/Inception%20network.png)

![Inception problem](/Notes/8.%20Case%20Studies/inception%20problem.png)

There is a problem of omputational cost since for eg in this case we end up having to do 120million multiplications.

To solve this, we will use 1x1 convolution to decrease the number of channels.

![Inception 1x1](/Notes/8.%20Case%20Studies/inception%201x1.png)

Inception Network is just the inception module repeated many times.

## MobileNet

Low compute enviroments

To decrease the number of mltiplications we use **Depthwise Seperable Convolution**

First we convolve layer by layer for each filter.

![Dephtwise convolution](/Notes/8.%20Case%20Studies/depthwise%20comvolutiom.png)

Then we do pointwise convolution to finally get a single channel output that we gety from a 3d convoltion.

![Pointwise Convolution](/Notes/8.%20Case%20Studies/POintwise%20convolution.png)

## MobileNetV2

It allows for a richer set of computations, while also keeping the memory small.

![MobileNetV2](/Notes/8.%20Case%20Studies/MobileNetv2.png)


## EfficientNet

Helps us scale up or down depending upon the resources of device being used.
We can change the resolution, change the depth or change the width of the neural network(size of the kernels and filters).
