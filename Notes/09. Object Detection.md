# Object Detection

## Object Localization

![Object Localization vs Detection](/Notes/9.%20Object%20Detection/Object%20localization%20vs%20detection.png)

Lets say we need to localize an object. For that we are gonna need 4 more outputs from our neural network namely bx, by, bh and bw. bx and by gives us the center of the box need to be drawn and bh and bw give us the width and the height of the box.

We will also need another output to detect if there are objects. Lets call it Pc. So, the output the following:

![Objecgt Localization](/Notes/9.%20Object%20Detection/Object%20localization.png)

The loss function used here was square loss for simplicity, we can use different loss functions for different outputs like log loss for c1 c2 and c3, square loss for bx by bh bw and logistic regression loss for Pc.

Also notice how for Pc = 0, we dont care about the other outputs so they are not included in the loss function.


## Landmark detection

We might need to detect points in the imag say for example the corner of the eye, lips, shoulder, elbows.

Detecting the position of such festures is the basis of AR technology, ood detection, position detection,etc.

We need to add outputs for lx and ly which the position of the desired location. we will need a labelled set with the location already labelled to train the network.

![Landmark detection](/Notes/9.%20Object%20Detection/Landmark%20Detection.png)

## Object Detection

### Sliding Windows
  
 In this, we essentially pass a small window over the image to get sections of the image which we pass through the CNN individually.
 
 Not very efficient but can be made more efficient by using convolution, we will get a grid whose each pixel will correspond to a square box on the image. The activation will determine the location of the box on the original image.

### Bounding Box prediction YOLO algorithm

 ![YOLO](/Notes/9.%20Object%20Detection/YOLO.png)


## Intersection Over Union

It gives us a measure of how accurate our bounding box is. 

![INtersection over union](/Notes/9.%20Object%20Detection/INtersection%20over%20union.png)

We can take ratio = 0.5 for benchmark of accuracy or for more strict enviroments, we can take a higher ratio.

## Non-Max supression

Sometimes, the algorithm may detect the same object multiple times leading to different boxes overlapping over the same object.

Each box has a prpobability of being current so for Non-max suppression we keep the box with the highest probability and supress the nearby boxes with low probability.

![Non-Max supression Algorithm](/Notes/9.%20Object%20Detection/non-max%20supression%20algorithm.png)

## Anchor Boxes

This helps us when the midpoints of 2 objects coincide. So for training, we need to add another set of outputs where each set corresponds to an anchor box of different shape.

![Anchor box algorithm](/Notes/9.%20Object%20Detection/Anchor%20boxes.png)

![Anchor box example](/Notes/9.%20Object%20Detection/Anchor%20boxes%20example.png)

There are a few cases this doesnt handle well, example if there are 3 overlapping objects instead of 2 or the shape of the 2 anchor boxes is the same.

## YOLO algorithm

![YOLO with anchor boxes](/Notes/9.%20Object%20Detection/YOLO%20with%20anchor%20boxes.png)

![YOLO non max supressed](/Notes/9.%20Object%20Detection/YOLO%20non%20max%20supressed.png)


## Semantic Segmentation with U-Net

This is for making a pixel by pixel detection of an object.
We take every single pixel and label is applied corresponding to the class it belongs to.

## Transpose Convolution

It gives us an output that is bigger than the input, for eg, a 2x2 image convolved with a filter of size 3x3 gives an output of 4x4.

Here, instead of putting the filter on the input, we put the filter on the output.

![Transpose convolution](/Notes/9.%20Object%20Detection/Transpose%20convoltuoin.png)

The kernel is multiplied by each pixel and the multiplied kernel is placed on the output.
Here, the stride taken is 2 to be able to completely fill the output.
For places wehre the output overlaps, the outputs are added.

## U-Net Architecture

![U-Net Architecture](/Notes/9.%20Object%20Detection/U_Net%20Architecture.png)